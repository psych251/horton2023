---
title: "Replication of Homo Silicus Study by John Horton (Work in progress)"
author: "Joon Sung Park (joonspk@stanford.edu)"
date: "October 8, 2023"
format:
  html:
    toc: true
    toc_depth: 3
---



<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

Many important theories in social science and policy design, such as the evolution of norms and the effects of policy interventions on a community, cannot be tested directly due to practical challenges of conducting large-scale longitudinal studies [1, 2, 3]. In response, one promising modern solution I have observed is the use of large language models to create proxies of human participants. This allows us to simulate the outcomes of studies that would otherwise be impossible to conduct. In my research program at the intersection of human-computer interaction and natural language processing, I have introduced methods to simulate general computational agents, known as generative agents [3, 4]. These agents leverage a large language model within a novel agent cognitive architecture to produce human-like behaviors at both the individual and group levels (e.g., user behaviors in online social media, NPC behaviors in Sims-inspired games). My current research interest focuses on demonstrating these agents as a scientific tool that can help us address many of the challenges in the social sciences that are best suited to being answered using simulations of human behavior.

In this replication study, I will delve into John Horton’s paper, “Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?”, which replicates existing social science experiments using large language models as proxies for human participants [5]. Horton’s work is among the notable early works [3, 4, 5, 9, 10] that aim to leverage the power of language models to simulate human participants in behavioral experiments. In his study, he replicates the findings of three experiments derived from Charness and Rabin (2002) [6], Kahneman, Knetsch, and Thaler (1986) [7], and Samuelson and Zeckhauser (1988) [8] by prompting a large language model. He finds that the language model-simulated participants, achieved by prompting the language model with a description of the study and then querying how it might behave in such an experiment, roughly matched the behavior of human subjects. My goal is to replicate Horton’s findings from all three experiments that he used.

However, in formulating large language models as a method for simulating social science experiments, I have noticed three important challenges that remain unaddressed in this emerging field: 1) ensuring the robustness of the simulated outcomes across different models and minor changes in the prompt, 2) understanding the population we are representing in our simulated outcomes, and 3) the challenges of benchmarking language model-simulated outcomes against published experiments that may be known to the model. In this replication study, I aim to extend Horton’s replication study to better understand the first of the three challenges I listed above 1) by replicating his results using variations of prompts that have semantic meaning in describing the experiments but are worded differently, and 2) by benchmarking different versions of large language models. The robustness of the results here, based on the changes in the model and prompt, is particularly important to ensure the replicability of the findings generated using a large language model.


## Work Cited

[1] Thomas Schelling. Micromotives and Macrobehavior (1978). <br>
[2] Eric Bonabeau. PNAS. Agent-based modeling: Methods and techniques for simulating human systems (2002) <br>
[3] Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. 2023. Generative agents: Interactive simulacra of human behavior. <br>
[4] Joon Sung Park, Lindsay Popowski, Carrie Cai, Mered- ith Ringel Morris, Percy Liang, and Michael S Bernstein. 2022. Social simulacra: Creating populated prototypes for social computing systems. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology, pages 1– 18. <br>
[5] John Horton. 2023. Large Language Models as Simulated Economic Agents: What can we learn from Homo Silicus? <br>
[6] Charness, Gary and Matthew Rabin, “Understanding social preferences with simple tests,” The quarterly journal of economics, 2002, 117 (3), 817–869. <br>
[7] Kahneman, Daniel, Jack L Knetsch, and Richard Thaler, “Fairness as a constraint on profit seeking: Entitlements in the market,” The American economic review, 1986, pp. 728–741. <br>
[8] Samuelson, William and Richard Zeckhauser, “Status quo bias in decision making,” Journal of risk and uncertainty, 1988, 1 (1), 7–59 <br>
[9] Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, David Wingate. Out of one, many: Using language models to simulate human samples. Political Analysis (2023) <br>
[10] Marcel Binz and Eric Schulz. Using cognitive psychology to understand GPT-3. PNAS (2023) <br>


<!-- ## Methods -->

<!-- ### Power Analysis -->

<!-- Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size.  Considerations of feasibility for selecting planned sample size. -->

<!-- ### Planned Sample -->

<!-- Planned sample size and/or termination rule, sampling frame, known demographics if any, preselection rules if any. -->

<!-- ### Materials -->

<!-- All materials - can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article. -->

<!-- ### Procedure	 -->

<!-- Can quote directly from original article - just put the text in quotations and note that this was followed precisely.  Or, quote directly and just point out exceptions to what was described in the original article. -->

<!-- ### Analysis Plan -->

<!-- Can also quote directly, though it is less often spelled out effectively for an analysis strategy section.  The key is to report an analysis strategy that is as close to the original - data cleaning rules, data exclusion rules, covariates, etc. - as possible.   -->

<!-- **Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do. -->

<!-- ### Differences from Original Study -->

<!-- Explicitly describe known differences in sample, setting, procedure, and analysis plan from original study.  The goal, of course, is to minimize those differences, but differences will inevitably occur.  Also, note whether such differences are anticipated to make a difference based on claims in the original article or subsequent published research on the conditions for obtaining the effect. -->

<!-- ### Methods Addendum (Post Data Collection) -->

<!-- You can comment this section out prior to final report with data collection. -->

<!-- #### Actual Sample -->
<!--   Sample size, demographics, data exclusions based on rules spelled out in analysis plan -->

<!-- #### Differences from pre-data collection methods plan -->
<!--   Any differences from what was described as the original plan, or “none”. -->


<!-- ## Results -->


<!-- ### Data preparation -->

<!-- Data preparation following the analysis plan. -->

<!-- ```{r include=F} -->
<!-- ### Data Preparation -->

<!-- #### Load Relevant Libraries and Functions -->

<!-- #### Import data -->

<!-- #### Data exclusion / filtering -->

<!-- #### Prepare data for analysis - create columns etc. -->
<!-- ``` -->

<!-- ### Confirmatory analysis -->

<!-- The analyses as specified in the analysis plan.   -->

<!-- *Side-by-side graph with original graph is ideal here* -->

<!-- ### Exploratory analyses -->

<!-- Any follow-up analyses desired (not required).   -->

<!-- ## Discussion -->

<!-- ### Summary of Replication Attempt -->

<!-- Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.   -->

<!-- ### Commentary -->

<!-- Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long. -->
